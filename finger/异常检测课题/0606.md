graphcore:
patches
问题设置：FSAD（Few-Shot Anomaly Detection，小样本异常检测）在训练期间，仅给出来自特定类别的 n 个正常样本的训练集，其中 n ≤ 8。在测试时，给出来自目标类别的正常或异常样本，异常检测模型应该预测图像是否异常，并在预测结果为异常时定位异常区域。

挑战：对于图 1(c) 中提出的 FSAD，我们尝试仅使用少量正常图像作为训练数据集来检测测试样本中的异常。关键挑战包括：
>1. 每个类别的训练数据集仅包含正常样本，即没有图像或像素级别的注释。（对于异常不进行标注？）
>2. 训练集中可提供的正常样本数量很少。在我们提出的场景中，训练样本少于 8 个。

动机：在现实的工业图像数据集（Bergmann 等人 (2019)；Jezek 等人 (2021)）中，某些类别下的图像极其相似。它们中的大多数可以通过简单的数据增强相互转换，例如图 2 中的元螺母和图 6 中的螺钉。例如，旋转增强可以有效地提供一个新的螺钉数据集。因此，面对第 2 节中陈述的挑战，我们自然倾向于通过数据增强获取更多数据。然后，特征记忆库（图 4）可以存储更多有用的特征。

算法1：ARG-PatchCore
>**输入**：  
    - ImageNet预训练模型 `ϕ`，用于特征提取。
    - 所有正常样本 `XN`。
    - 数据增强操作符 `α`，例如旋转。
    - 补丁特征提取器 `P`，用于从图像中提取特征。
    - 记忆库大小目标 `l`，即希望记忆库中存储的特征数量。
    - 随机线性投影 `ψ`，用于核心集（coreset）采样。
> **初始化**：
    - 记忆库 `M` 初始化为空集。
>**特征提取与增强**： 
    - 对于正常样本集 `XN` 中的每个样本 `xi`：
    - 应用数据增强操作 `α` 到 `xi`，得到增强后的样本 `xg_i`。
    - 使用预训练模型 `ϕ` 提取原始样本和增强样本的特征，并将这些特征通过特征提取器 `P` 处理后加入到记忆库 `M` 中。
>**核心集采样**：  
    - 初始化核心集 `MC` 为空集。
    - 进行 `l` 次迭代，每次迭代中：
    - 从未被选中的记忆中找到与核心集中所有点距离最远的点 `mi`。
    - 更新核心集 `MC`，将其加入。
>**输出**： 
    - 最终的核心集 `MC` 作为Patch-level增强记忆库 `M`。

图表示过程：将$H \times W\times 3$的图像表示为一个图结构
>1. **图像分割**：
    - 首先，将正常样本图像均匀分割成多个小块（patches），每个小块可以被视为图中的一个节点。
>2. **特征向量化**：  
    - 每个图像小块（或称为patch）被转换为一个特征向量，这些特征向量构成了图中节点的属性。
>3. **节点和边的创建**：  
    - 将这些特征向量视为图中的节点，对于每个节点，确定其K个最近邻节点，并在这些节点之间创建有向边。通常，边是从邻居节点指向中心节点。
>4. **图的构建**：  
    - 通过上述步骤，整个图像可以被表示为一个图 G=(V,E)，其中 V 是节点集合，E 是边集合。
>5. **图特征处理**：  
    - 使用图神经网络（GNN）对图中的节点特征进行处理。GNN能够通过聚合邻居节点的信息来更新每个节点的特征，从而捕捉到图像中的局部和全局结构信息。
>6. **图卷积网络（GCN）**：  
    - 论文中提到使用图卷积网络作为特征提取器。GCN通过在节点间传递信息来更新节点特征，使用max-pooling或其他聚合函数来整合邻居特征。
>7. **特征更新**：  
    - 在GCN中，每个节点的特征更新函数通常包括一个聚合步骤，用于收集邻居节点的特征，以及一个更新步骤，用于将聚合的特征与当前节点的特征结合。
>8. **旋转等距不变性**：  
    - 论文中提出的图表示方法特别强调旋转等距不变性，即图像经过旋转变换后，其图表示应该保持一致性。这对于工业视觉系统中的异常检测尤为重要，因为产品可能以不同角度出现。
>9. **异常检测**：  
    - 在测试阶段，通过比较测试图像的图表示与正常样本的图表示之间的差异，可以检测出异常。如果差异超过某个阈值，则认为测试图像包含异常

问题一：文中提到的视觉等距不变特征（Vision Isometric Invariant Feature, VIIF）是在构建特征库的时候利用GCN实现的吗？
问题二：异常得分是如何计算的：对于每个patch，是不是先在特征库中找到与patch最相似的特征，然后再计算它们的距离来判断是否是异常的patch
问题三：

了解GraphCore的图神经网络结构
了解PatchCore的异常定位方式，与其他方法的对比 simplenet、padim
异常得分、阈值计算方式
line:162 before _embed shape
torch.Size([2, 3, 224, 224])
layers_to_extract_from= ('layer2', 'layer3')
input_shape= (3, 224, 224)

after feature_aggregator
经过feature_aggregator也就是resnet模型提取特征得到的features是一个字典，键包括later2,layer3两个
features[layer2]的shape为torch.Size([2, 512, 28, 28])
features[layer3]的shape为torch.Size([2, 1024, 14, 14])\

经过特定层数的选择后得到features是一个list，它的长度为2
features[0].shape = torch.Size([2, 512, 28, 28])
features[1].shape = torch.Size([2, 1024, 14, 14])

feature_dimension= [512, 1024]
pretrain_embed_dimension=1024

经过patchify后，得到的是一个python list，长度为2，每一个元素又是一个tuple
features\[0\]\[0\].shape=torch.Size([2, 784, 512, 3, 3])
features\[0\]\[1\] =\[28, 28\]
\
features\[1\]\[0\].shape=torch.Size([2, 196, 1024, 3, 3])
features\[1\]\[1\] =\[14, 14\]

然后如文中所提到的，对由于features\[0\]和features\[1\]的大小不同，对features\[1\]使用双线性重采样使得二者对齐
features\[0\].shape=torch.Size([2, 784, 512, 3, 3])
features\[1\].shape=torch.Size([2, 784, 1024, 3, 3])

然后进入preprocessing进行处理，这一步主要进行自适应平均池化得到的features的shape为
features.shape = torch.Size([1568,2, 1024])

最后再进行preadapt_aggregator,得到的features的shape为
features.shape = torch.Size([1568, 1024])